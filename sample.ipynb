{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb3a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface\n",
    "from transformers import AutoFeatureExtractor, AutoModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "# Visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "# Others\n",
    "from typing import Tuple\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Logging\n",
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "\n",
    "# Config visualization output\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "sns.set_palette(sns.color_palette([\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]))\n",
    "\n",
    "# Make computations repeatable\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Compute on gpu if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Run length encoding\n",
    "def rle_encoding(x):\n",
    "    '''\n",
    "    x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns run length as list\n",
    "    '''\n",
    "    dots = np.where(x.T.flatten()==1)[0] # .T sets Fortran order down-then-right\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b+1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "# Dice score\n",
    "def dice_score(y_true, y_pred):\n",
    "    return torch.sum(y_pred[y_true==1])*2.0 / (torch.sum(y_pred) + torch.sum(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e6cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.trans_resunet import TransResUNet\n",
    "import ml_collections\n",
    "from torchinfo import summary\n",
    "\n",
    "def get_r50_b16_config():\n",
    "    \"\"\"Returns the ViT-B/16 configuration.\"\"\"\n",
    "    config = ml_collections.ConfigDict()\n",
    "    \n",
    "    config.image_size = (480, 640)\n",
    "    config.n_classes = 1\n",
    "    config.pre_trained_path = 'imagenet21k_R50+ViT-B_16.npz'\n",
    "    \n",
    "    config.resnet = ml_collections.ConfigDict()\n",
    "    # Using three bottleneck blocks results in a downscaling of 2^(1 + 3)=16 which\n",
    "    # results in an effective patch size of /16.\n",
    "    config.resnet.num_layers = (3, 4, 9)\n",
    "    config.resnet.width_factor = 1\n",
    "    \n",
    "    config.transformer = ml_collections.ConfigDict()\n",
    "    config.transformer.num_special_tokens = 1\n",
    "    config.transformer.patch_size = 16\n",
    "    config.transformer.hidden_size = 768\n",
    "    config.transformer.mlp_dim = 3072\n",
    "    config.transformer.num_heads = 12\n",
    "    config.transformer.num_layers = 12\n",
    "    config.transformer.attention_dropout_rate = 0.0\n",
    "    config.transformer.dropout_rate = 0.1\n",
    "    \n",
    "    return config\n",
    "\n",
    "def get_r50_l32_config():\n",
    "    \"\"\"Returns the ViT-L/32 configuration.\"\"\"\n",
    "    config = ml_collections.ConfigDict()\n",
    "    \n",
    "    config.image_size = (480, 640)\n",
    "    config.n_classes = 1\n",
    "    config.pre_trained_path = 'imagenet21k_R50+ViT-L_32.npz'\n",
    "    \n",
    "    config.resnet = ml_collections.ConfigDict()\n",
    "    # Using four bottleneck blocks results in a downscaling of 2^(1 + 4)=32 which\n",
    "    # results in an effective patch size of /32.\n",
    "    config.resnet.num_layers = (3, 4, 6, 3)\n",
    "    config.resnet.width_factor = 1\n",
    "    \n",
    "    config.transformer = ml_collections.ConfigDict()\n",
    "    config.transformer.num_special_tokens = 1\n",
    "    config.transformer.patch_size = 32\n",
    "    config.transformer.hidden_size = 1024\n",
    "    config.transformer.mlp_dim = 4096\n",
    "    config.transformer.num_heads = 16\n",
    "    config.transformer.num_layers = 24\n",
    "    config.transformer.attention_dropout_rate = 0.0\n",
    "    config.transformer.dropout_rate = 0.1\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc559d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 1601, 768])\n",
      "Position embedding grid-size from [14, 14] to [40, 40]\n"
     ]
    }
   ],
   "source": [
    "# config = get_r50_l32_config()\n",
    "config = get_r50_b16_config()\n",
    "net = TransResUNet(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee41489-ae98-4a52-a6ac-174abf0c9f36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "TransResUNet                                                 --                        --\n",
       "├─HybridVit: 1                                               --                        --\n",
       "│    └─Encoder: 2                                            --                        --\n",
       "│    │    └─ModuleList: 3-1                                  --                        --\n",
       "├─ModuleList: 1-1                                            --                        --\n",
       "├─HybridVit: 1-2                                             [4, 1201, 768]            --\n",
       "│    └─Embeddings: 2-1                                       [4, 1201, 768]            --\n",
       "│    │    └─ResNetV2: 3-2                                    [4, 1024, 30, 40]         --\n",
       "│    │    │    └─Sequential: 4-1                             [4, 64, 240, 320]         --\n",
       "│    │    │    │    └─StdConv2d: 5-1                         [4, 64, 240, 320]         9,408\n",
       "│    │    │    │    └─GroupNorm: 5-2                         [4, 64, 240, 320]         128\n",
       "│    │    │    │    └─ReLU: 5-3                              [4, 64, 240, 320]         --\n",
       "│    │    │    └─MaxPool2d: 4-2                              [4, 64, 119, 159]         --\n",
       "│    │    │    └─Sequential: 4                               --                        --\n",
       "│    │    │    │    └─ResNetStage: 5-4                       [4, 256, 119, 159]        215,808\n",
       "│    │    │    │    └─ResNetStage: 5-5                       [4, 512, 60, 80]          1,219,584\n",
       "│    │    │    │    └─ResNetStage: 5-6                       [4, 1024, 30, 40]         10,449,920\n",
       "│    │    └─Conv2d: 3-3                                      [4, 768, 30, 40]          787,200\n",
       "│    │    └─Dropout: 3-4                                     [4, 1201, 768]            --\n",
       "│    └─Encoder: 2-2                                          [4, 1201, 768]            --\n",
       "│    │    └─ModuleList: 3-1                                  --                        --\n",
       "│    │    │    └─Block: 4-3                                  [4, 1201, 768]            --\n",
       "│    │    │    │    └─LayerNorm: 5-7                         [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Attention: 5-8                         [4, 1201, 768]            2,362,368\n",
       "│    │    │    │    └─LayerNorm: 5-9                         [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Mlp: 5-10                              [4, 1201, 768]            4,722,432\n",
       "│    │    │    └─Block: 4-4                                  [4, 1201, 768]            --\n",
       "│    │    │    │    └─LayerNorm: 5-11                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Attention: 5-12                        [4, 1201, 768]            2,362,368\n",
       "│    │    │    │    └─LayerNorm: 5-13                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Mlp: 5-14                              [4, 1201, 768]            4,722,432\n",
       "│    │    │    └─Block: 4-5                                  [4, 1201, 768]            --\n",
       "│    │    │    │    └─LayerNorm: 5-15                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Attention: 5-16                        [4, 1201, 768]            2,362,368\n",
       "│    │    │    │    └─LayerNorm: 5-17                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Mlp: 5-18                              [4, 1201, 768]            4,722,432\n",
       "│    │    │    └─Block: 4-6                                  [4, 1201, 768]            --\n",
       "│    │    │    │    └─LayerNorm: 5-19                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Attention: 5-20                        [4, 1201, 768]            2,362,368\n",
       "│    │    │    │    └─LayerNorm: 5-21                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Mlp: 5-22                              [4, 1201, 768]            4,722,432\n",
       "│    │    │    └─Block: 4-7                                  [4, 1201, 768]            --\n",
       "│    │    │    │    └─LayerNorm: 5-23                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Attention: 5-24                        [4, 1201, 768]            2,362,368\n",
       "│    │    │    │    └─LayerNorm: 5-25                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Mlp: 5-26                              [4, 1201, 768]            4,722,432\n",
       "│    │    │    └─Block: 4-8                                  [4, 1201, 768]            --\n",
       "│    │    │    │    └─LayerNorm: 5-27                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Attention: 5-28                        [4, 1201, 768]            2,362,368\n",
       "│    │    │    │    └─LayerNorm: 5-29                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Mlp: 5-30                              [4, 1201, 768]            4,722,432\n",
       "│    │    │    └─Block: 4-9                                  [4, 1201, 768]            --\n",
       "│    │    │    │    └─LayerNorm: 5-31                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Attention: 5-32                        [4, 1201, 768]            2,362,368\n",
       "│    │    │    │    └─LayerNorm: 5-33                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Mlp: 5-34                              [4, 1201, 768]            4,722,432\n",
       "│    │    │    └─Block: 4-10                                 [4, 1201, 768]            --\n",
       "│    │    │    │    └─LayerNorm: 5-35                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Attention: 5-36                        [4, 1201, 768]            2,362,368\n",
       "│    │    │    │    └─LayerNorm: 5-37                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Mlp: 5-38                              [4, 1201, 768]            4,722,432\n",
       "│    │    │    └─Block: 4-11                                 [4, 1201, 768]            --\n",
       "│    │    │    │    └─LayerNorm: 5-39                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Attention: 5-40                        [4, 1201, 768]            2,362,368\n",
       "│    │    │    │    └─LayerNorm: 5-41                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Mlp: 5-42                              [4, 1201, 768]            4,722,432\n",
       "│    │    │    └─Block: 4-12                                 [4, 1201, 768]            --\n",
       "│    │    │    │    └─LayerNorm: 5-43                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Attention: 5-44                        [4, 1201, 768]            2,362,368\n",
       "│    │    │    │    └─LayerNorm: 5-45                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Mlp: 5-46                              [4, 1201, 768]            4,722,432\n",
       "│    │    │    └─Block: 4-13                                 [4, 1201, 768]            --\n",
       "│    │    │    │    └─LayerNorm: 5-47                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Attention: 5-48                        [4, 1201, 768]            2,362,368\n",
       "│    │    │    │    └─LayerNorm: 5-49                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Mlp: 5-50                              [4, 1201, 768]            4,722,432\n",
       "│    │    │    └─Block: 4-14                                 [4, 1201, 768]            --\n",
       "│    │    │    │    └─LayerNorm: 5-51                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Attention: 5-52                        [4, 1201, 768]            2,362,368\n",
       "│    │    │    │    └─LayerNorm: 5-53                        [4, 1201, 768]            1,536\n",
       "│    │    │    │    └─Mlp: 5-54                              [4, 1201, 768]            4,722,432\n",
       "│    │    └─LayerNorm: 3-5                                   [4, 1201, 768]            1,536\n",
       "├─ModuleList: 1-1                                            --                        --\n",
       "│    └─ResDecoderBlock: 2-3                                  [4, 384, 60, 80]          --\n",
       "│    │    └─ConvTranspose2d: 3-6                             [4, 768, 60, 80]          2,360,064\n",
       "│    │    └─ResConv: 3-7                                     [4, 384, 60, 80]          --\n",
       "│    │    │    └─Sequential: 4-15                            [4, 384, 60, 80]          --\n",
       "│    │    │    │    └─BatchNorm2d: 5-55                      [4, 1280, 60, 80]         2,560\n",
       "│    │    │    │    └─ReLU: 5-56                             [4, 1280, 60, 80]         --\n",
       "│    │    │    │    └─Conv2d: 5-57                           [4, 384, 60, 80]          4,424,064\n",
       "│    │    │    │    └─BatchNorm2d: 5-58                      [4, 384, 60, 80]          768\n",
       "│    │    │    │    └─ReLU: 5-59                             [4, 384, 60, 80]          --\n",
       "│    │    │    │    └─Conv2d: 5-60                           [4, 384, 60, 80]          1,327,488\n",
       "│    │    │    └─Sequential: 4-16                            [4, 384, 60, 80]          --\n",
       "│    │    │    │    └─Conv2d: 5-61                           [4, 384, 60, 80]          4,424,064\n",
       "│    │    │    │    └─BatchNorm2d: 5-62                      [4, 384, 60, 80]          768\n",
       "│    └─ResDecoderBlock: 2-4                                  [4, 192, 120, 160]        --\n",
       "│    │    └─ConvTranspose2d: 3-8                             [4, 384, 120, 160]        590,208\n",
       "│    │    └─ResConv: 3-9                                     [4, 192, 120, 160]        --\n",
       "│    │    │    └─Sequential: 4-17                            [4, 192, 120, 160]        --\n",
       "│    │    │    │    └─BatchNorm2d: 5-63                      [4, 640, 120, 160]        1,280\n",
       "│    │    │    │    └─ReLU: 5-64                             [4, 640, 120, 160]        --\n",
       "│    │    │    │    └─Conv2d: 5-65                           [4, 192, 120, 160]        1,106,112\n",
       "│    │    │    │    └─BatchNorm2d: 5-66                      [4, 192, 120, 160]        384\n",
       "│    │    │    │    └─ReLU: 5-67                             [4, 192, 120, 160]        --\n",
       "│    │    │    │    └─Conv2d: 5-68                           [4, 192, 120, 160]        331,968\n",
       "│    │    │    └─Sequential: 4-18                            [4, 192, 120, 160]        --\n",
       "│    │    │    │    └─Conv2d: 5-69                           [4, 192, 120, 160]        1,106,112\n",
       "│    │    │    │    └─BatchNorm2d: 5-70                      [4, 192, 120, 160]        384\n",
       "│    └─ResDecoderBlock: 2-5                                  [4, 96, 240, 320]         --\n",
       "│    │    └─ConvTranspose2d: 3-10                            [4, 192, 240, 320]        147,648\n",
       "│    │    └─ResConv: 3-11                                    [4, 96, 240, 320]         --\n",
       "│    │    │    └─Sequential: 4-19                            [4, 96, 240, 320]         --\n",
       "│    │    │    │    └─BatchNorm2d: 5-71                      [4, 256, 240, 320]        512\n",
       "│    │    │    │    └─ReLU: 5-72                             [4, 256, 240, 320]        --\n",
       "│    │    │    │    └─Conv2d: 5-73                           [4, 96, 240, 320]         221,280\n",
       "│    │    │    │    └─BatchNorm2d: 5-74                      [4, 96, 240, 320]         192\n",
       "│    │    │    │    └─ReLU: 5-75                             [4, 96, 240, 320]         --\n",
       "│    │    │    │    └─Conv2d: 5-76                           [4, 96, 240, 320]         83,040\n",
       "│    │    │    └─Sequential: 4-20                            [4, 96, 240, 320]         --\n",
       "│    │    │    │    └─Conv2d: 5-77                           [4, 96, 240, 320]         221,280\n",
       "│    │    │    │    └─BatchNorm2d: 5-78                      [4, 96, 240, 320]         192\n",
       "│    └─ResDecoderBlock: 2-6                                  [4, 48, 480, 640]         --\n",
       "│    │    └─ConvTranspose2d: 3-12                            [4, 96, 480, 640]         36,960\n",
       "│    │    └─ResConv: 3-13                                    [4, 48, 480, 640]         --\n",
       "│    │    │    └─Sequential: 4-21                            [4, 48, 480, 640]         --\n",
       "│    │    │    │    └─BatchNorm2d: 5-79                      [4, 96, 480, 640]         192\n",
       "│    │    │    │    └─ReLU: 5-80                             [4, 96, 480, 640]         --\n",
       "│    │    │    │    └─Conv2d: 5-81                           [4, 48, 480, 640]         41,520\n",
       "│    │    │    │    └─BatchNorm2d: 5-82                      [4, 48, 480, 640]         96\n",
       "│    │    │    │    └─ReLU: 5-83                             [4, 48, 480, 640]         --\n",
       "│    │    │    │    └─Conv2d: 5-84                           [4, 48, 480, 640]         20,784\n",
       "│    │    │    └─Sequential: 4-22                            [4, 48, 480, 640]         --\n",
       "│    │    │    │    └─Conv2d: 5-85                           [4, 48, 480, 640]         41,520\n",
       "│    │    │    │    └─BatchNorm2d: 5-86                      [4, 48, 480, 640]         96\n",
       "├─Conv2d: 1-3                                                [4, 1, 480, 640]          49\n",
       "==============================================================================================================\n",
       "Total params: 114,229,633\n",
       "Trainable params: 114,229,633\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 961.45\n",
       "==============================================================================================================\n",
       "Input size (MB): 14.75\n",
       "Forward/backward pass size (MB): 16756.33\n",
       "Params size (MB): 456.92\n",
       "Estimated Total Size (MB): 17228.00\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(net, (4, 3, 480, 640), depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b16804-d052-4bfa-8556-c49c2645f2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
